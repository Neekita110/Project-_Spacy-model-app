# Optimized NER Pipelines with SpaCy & Hugging Face Transformers | FastAPI Async App

## Overview
This project builds an interactive Q&A system that enables users to upload PDFs and receive insightful answers to their queries. Leveraging transformer-based models for embeddings, the app efficiently stores and retrieves vectors using Qdrant, an open-source vector database. The Q&A system integrates advanced language models, including Phi-2 and Ollama, within Langchain, significantly reducing query response time by 25%. The user interface, designed with Streamlit, provides a seamless experience for document analysis and insight extraction.

## Features
- **PDF Q&A Functionality**: Users can upload PDF documents and query for answers, allowing streamlined interaction with large text data.
- **Efficient Embedding Storage**: Transformer-based embeddings are stored in Qdrant, optimizing retrieval and maintaining accuracy.
- **High-Performance Query System**: Integrated with Langchain, leveraging Phi-2 and Ollama models, reducing response times by 25%.
- **Streamlit UI**: A user-friendly interface for uploading documents, inputting questions, and receiving real-time answers.

## Technical Stack
- **Languages**: Python
- **Libraries**: SpaCy, Hugging Face Transformers, Langchain, Qdrant, FastAPI, Streamlit
- **Models**: Phi-2, Ollama, and other transformer-based models
- **Tools**: Qdrant (vector storage), Streamlit (UI), FastAPI (backend)

## Results
- Achieved a 25% improvement in query response time, enhancing user experience and efficiency in document analysis.

